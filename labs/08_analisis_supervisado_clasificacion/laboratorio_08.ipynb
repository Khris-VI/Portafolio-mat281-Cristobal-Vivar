{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/usm.jpg\" width=\"480\" height=\"240\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT281 - Laboratorio N°02\n",
    "\n",
    "## Objetivos del laboratorio\n",
    "\n",
    "* Reforzar conceptos básicos de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenidos\n",
    "\n",
    "* [Problema 01](#p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1'></a>\n",
    "## I.- Problema 01\n",
    "\n",
    "\n",
    "<img src=\"https://www.xenonstack.com/wp-content/uploads/xenonstack-credit-card-fraud-detection.png\" width=\"360\" height=\"360\" align=\"center\"/>\n",
    "\n",
    "\n",
    "El conjunto de datos se denomina `creditcard.csv` y consta de varias columnas con información acerca del fraude de tarjetas de crédito, en donde la columna **Class** corresponde a: 0 si no es un fraude y 1 si es un fraude.\n",
    "\n",
    "En este ejercicio se trabajará el problemas de  clases desbalancedas. Veamos las primeras cinco filas dle conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.249999</td>\n",
       "      <td>-1.221637</td>\n",
       "      <td>0.383930</td>\n",
       "      <td>-1.234899</td>\n",
       "      <td>-1.485419</td>\n",
       "      <td>-0.753230</td>\n",
       "      <td>-0.689405</td>\n",
       "      <td>-0.227487</td>\n",
       "      <td>-2.094011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231809</td>\n",
       "      <td>-0.483285</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.392831</td>\n",
       "      <td>0.161135</td>\n",
       "      <td>-0.354990</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.384978</td>\n",
       "      <td>0.616109</td>\n",
       "      <td>-0.874300</td>\n",
       "      <td>-0.094019</td>\n",
       "      <td>2.924584</td>\n",
       "      <td>3.317027</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>-0.558895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049924</td>\n",
       "      <td>0.238422</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>-0.767315</td>\n",
       "      <td>-0.492208</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.103215</td>\n",
       "      <td>-0.040296</td>\n",
       "      <td>1.267332</td>\n",
       "      <td>1.289091</td>\n",
       "      <td>-0.735997</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>-0.586057</td>\n",
       "      <td>0.189380</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>0.364298</td>\n",
       "      <td>-0.382261</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "2  10.0  1.249999 -1.221637  0.383930 -1.234899 -1.485419 -0.753230 -0.689405   \n",
       "3  10.0  0.384978  0.616109 -0.874300 -0.094019  2.924584  3.317027  0.470455   \n",
       "4  12.0  1.103215 -0.040296  1.267332  1.289091 -0.735997  0.288069 -0.586057   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "2 -0.227487 -2.094011  ... -0.231809 -0.483285  0.084668  0.392831  0.161135   \n",
       "3  0.538247 -0.558895  ...  0.049924  0.238422  0.009130  0.996710 -0.767315   \n",
       "4  0.189380  0.782333  ... -0.024612  0.196002  0.013802  0.103758  0.364298   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1 -0.257237  0.034507  0.005168    4.99      0  \n",
       "2 -0.354990  0.026416  0.042422  121.50      0  \n",
       "3 -0.492208  0.042472 -0.054337    9.99      0  \n",
       "4 -0.382261  0.092809  0.037051   12.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargar datos\n",
    "df = pd.read_csv(os.path.join(\"data\",\"creditcard.csv\"), sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos el total de fraudes respecto a los casos que nos son fraudes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraude</th>\n",
       "      <th>total</th>\n",
       "      <th>porcentaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>50000</td>\n",
       "      <td>99.025588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>si</td>\n",
       "      <td>492</td>\n",
       "      <td>0.974412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fraude  total  porcentaje\n",
       "0     no  50000   99.025588\n",
       "1     si    492    0.974412"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcular proporciones\n",
    "df_count = pd.DataFrame()\n",
    "df_count[\"fraude\"] =[\"no\",\"si\"]\n",
    "df_count[\"total\"] = df[\"Class\"].value_counts() \n",
    "df_count[\"porcentaje\"] = 100*df_count[\"total\"] /df_count[\"total\"] .sum()\n",
    "\n",
    "df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que menos del 1% corresponde a registros frudulentos. La pregunta que surgen son:\n",
    "\n",
    "* ¿ Cómo deben ser el conjunto de entrenamiento y de testeo?\n",
    "* ¿ Qué modelos ocupar?\n",
    "* ¿ Qué métricas ocupar?\n",
    "\n",
    "Por ejemplo, analicemos el modelos de regresión logística y apliquemos el procedimiento estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961181969420898"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datos \n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "\n",
    "# Creando el modelo\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    " \n",
    "# predecir\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# calcular accuracy\n",
    "accuracy_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general el modelo tiene un **accuracy** del 99,9%, es decir, un podría suponer que el modelo predice casi perfectamente, pero eso esta lejos de ser así.  Para ver por qué es necesario seguir los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cambiar la métrica de rendimiento\n",
    "\n",
    "El primer paso es comparar con distintas métricas, para eso ocupemos las 4 métricas clásicas abordadas en el curso:\n",
    "* accuracy\n",
    "* precision\n",
    "* recall\n",
    "* f-score\n",
    "\n",
    "En este punto deberá poner las métricas correspondientes y comentar sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusion:\n",
      " \n",
      "[[12471    16]\n",
      " [   33   103]]\n",
      "\n",
      "Metricas:\n",
      " \n",
      "accuracy:    0.9961181969420898\n",
      "recall:      0.7573529411764706\n",
      "precision:   0.865546218487395\n",
      "f-score:     0.807843137254902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "y_true =  list(y_test)\n",
    "y_pred = list(lr.predict(X_test))\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',accuracy_score(y_test, lr_pred))\n",
    "print('recall:     ',recall_score(y_test, lr_pred))\n",
    "print('precision:  ',precision_score(y_test, lr_pred))\n",
    "print('f-score:    ',f1_score(y_test, lr_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios de Resultados 1\n",
    "\n",
    "En el contexto del problema, como la clase de fraude es minuscula en comparación a la clase no fraude, la métrica acurracy no es un buen estimador de que tan buena fue la predicción (Es una métrica muy suceptible a diferencias grandes en la cantidad de valores de cada clase). Aun cuando la métrica acurracy fue alta (99,6 %), con lo que se dijo anteriormente, conviene mirar las demás métricas para obtener un mejor análisis para este problema. Si miramos la métrica recall:\n",
    "\n",
    "$$recall(y,\\hat{y}) = \\dfrac{TP}{TP+FN}$$\n",
    "\n",
    "El valor que se obtuvo de un 75%, nos estaría de la totalidad de las tajetas con fraude, solo un 75% se predijeron correctamente. Debido a la seriedad de un fraude de una tarjeta bancaria, a mi opinión un indíce de predicción correcta de fraude del 75% no es suficiente para un banco. \n",
    "\n",
    "También observando la precision se tiene que de la totalidad de las tarjetas que se predijeron fraude, solo un 86% en verdad lo eran, denuevo, debido a la seriedad de los fraudes, en mi opinión no es suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cambiar algoritmo\n",
    "\n",
    "El segundo paso es comparar con distintos modelos. Debe tener en cuenta que el modelo ocupaod resuelva el problema supervisado de clasificación.\n",
    "\n",
    "En este punto deberá ajustar un modelo de **random forest**, aplicar las métricas y comparar con el modelo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "rfc =  RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1).fit(X_train, y_train) # algoritmo random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusion:\n",
      " \n",
      "[[12485     2]\n",
      " [   56    80]]\n",
      "\n",
      "Metricas:\n",
      " \n",
      "accuracy:    0.9954052127069635\n",
      "recall:      0.5882352941176471\n",
      "precision:   0.975609756097561\n",
      "f-score:     0.7339449541284403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "\n",
    "y_true =  list(y_test)\n",
    "y_pred = list(rfc.predict(X_test)) # predicciones con random forest\n",
    "\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',accuracy_score(y_true,y_pred))\n",
    "print('recall:     ',recall_score(y_true,y_pred))\n",
    "print('precision:  ',precision_score(y_true,y_pred))\n",
    "print('f-score:    ',f1_score(y_true,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios de Resultados 2\n",
    "\n",
    "AL igual que en 1, el acurracy es alto solo por la gran diferencia en la cantidad de cada clase, así que conviene mirar las demás métricas.\n",
    "\n",
    "En comparación con 1, la métrica recall bajó hasta un 60% denuevo diciendo que solo se predijeron correctamente 60& de las tarjetas con fraude. En mi opinión, aunque en 1 mencioné que era malo que solo se tuviera un 75%, en esta predicción se obtuvo aun más bajo, por lo que preferíria el metodo de 1.\n",
    "\n",
    "Se observa también que la métrica precision fue de 97-98% muy cercano al 100%, pero como está métrica mide cuantos datos de los que se dijo que eran fraude en realidad lo erán, el hecho que el recall haya sido tan bajo le quita mucha validez al método (esto también se ve reflejado en el f-score que se puede entender como algun tipo de media entre recall y precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Técnicas de remuestreo: sobremuestreo de clase minoritaria\n",
    "\n",
    "El tercer paso es ocupar ténicas de remuestreo, pero sobre la clase minoritaria. Esto significa que mediantes ténicas de remuestreo trataremos de equiparar el número de elementos de la clase minoritaria a la clase mayoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    37513\n",
       "0    37513\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenar el conjunto de entrenamiento\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separar las clases\n",
    "not_fraud = X[X.Class==0]\n",
    "fraud = X[X.Class==1]\n",
    "\n",
    "# remuestrear  clase minoritaria\n",
    "fraud_upsampled = resample(fraud,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# recombinar resultados\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "\n",
    "# chequear el número de elementos por clases\n",
    "upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de entrenamiento sobre-balanceados\n",
    "y_train = upsampled.Class\n",
    "X_train = upsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupando estos nuevos conjunto de entrenamientos, vuelva a aplicar el modelos de regresión logística y calcule las correspondientes métricas. Además, justifique las ventajas y desventjas de este procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusion:\n",
      " \n",
      "[[12200   287]\n",
      " [   12   124]]\n",
      "\n",
      "Metricas:\n",
      " \n",
      "accuracy:    0.976313079299691\n",
      "recall:      0.9117647058823529\n",
      "precision:   0.30170316301703165\n",
      "f-score:     0.45338208409506403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train) # algoritmo de regresion logistica\n",
    "\n",
    "# metrics\n",
    "\n",
    "y_true =  list(y_test)\n",
    "y_pred = list(upsampled.predict(X_test))\n",
    "\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',accuracy_score(y_true,y_pred))\n",
    "print('recall:     ',recall_score(y_true,y_pred))\n",
    "print('precision:  ',precision_score(y_true,y_pred))\n",
    "print('f-score:    ',f1_score(y_true,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios de Resultados 3\n",
    "\n",
    "En este caso notamos una disminución considerable en la métrica precisión, causada por el aumento considerable en la catidad de los datos de la clase fraude. Observamos también que acurracy se mantuvo alto y recall subió, lo que puede ser beneficial para este problema en especifico.\n",
    "Debido a la gran dierencia que hay en la cantidad de valores de cada clase, al ocupar esta técnica podríamos estar afectando demasiado la veracidad de la clasificación. Al agregar una magnitud tan grande de datos, el peso que tienen los datos originales es muy poco en la clasificación.\n",
    "Aun así, una ventaja de este metodo es que es más fácil analizar datos balanceados de manera segura, las métricas serán más representativas en datos balanceados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Técnicas de remuestreo - Ejemplo de clase mayoritaria\n",
    "\n",
    "El cuarto paso es ocupar ténicas de remuestreo, pero sobre la clase mayoritaria. Esto significa que mediantes ténicas de remuestreo trataremos de equiparar el número de elementos de la clase mayoritaria  a la clase minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    356\n",
       "0    356\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remuestreo clase mayoritaria\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fraud), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# recombinar resultados\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
    "\n",
    "# chequear el número de elementos por clases\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de entrenamiento sub-balanceados\n",
    "\n",
    "y_train = downsampled.Class\n",
    "X_train = downsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupando estos nuevos conjunto de entrenamientos, vuelva a aplicar el modelos de regresión logística y calcule las correspondientes métricas. Además, justifique las ventajas y desventjas de este procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusion:\n",
      " \n",
      "[[12216   271]\n",
      " [   16   120]]\n",
      "\n",
      "Metricas:\n",
      " \n",
      "accuracy:    0.9772637249465261\n",
      "recall:      0.8823529411764706\n",
      "precision:   0.3069053708439898\n",
      "f-score:     0.45540796963946867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersampled = LogisticRegression(solver='liblinear').fit(X_train, y_train) # modelo de regresi+on logística\n",
    "\n",
    "# metrics\n",
    "\n",
    "y_true =  list(y_test)\n",
    "y_pred = list(undersampled.predict(X_test))\n",
    "\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',accuracy_score(y_true,y_pred))\n",
    "print('recall:     ',recall_score(y_true,y_pred))\n",
    "print('precision:  ',precision_score(y_true,y_pred))\n",
    "print('f-score:    ',f1_score(y_true,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios de Resultados 4\n",
    "\n",
    "Se puede observar una pequeña disminución en recall en comparación con 3 pero las demás metricas se mantuvieron parecidas.\n",
    "\n",
    "Este método puede ser muy perjudicial por el hecho de que estamos quitando datos del análisis, en este caso se perdieron más de 30000 datos para disminuir las clase mayoritaria. Esta técnica se podría usar cuando la totalidad de los datos es sifnificativamente mayor a la diferencia entre las clases. Una ventaja al igual que en 3, es que es más hacer un análisis con una clasificación de datos balanceada, las métricas entregan información más represntativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusiones\n",
    "\n",
    "Para finalizar el laboratorio, debe realizar un análisis comparativo con los disintos resultados obtenidos  en los pasos 1-4. Saque sus propias conclusiones del caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que en todos los casos la métrica acurracy se mantuvo sobre el 97% lo que me hace pensar que no es un muy buen indicador de validez de técnicas. \n",
    "\n",
    "Debido al contexto del problema, creo importante ponerle enfasis al estudio de recall, puesto que nos está entregando información de buena oprediccion de fraudes. Con esto, el método 3 fue el obtuvo un mayor valor con un 91%, pero se contrasto con el hecho de agregar una cantidad de casi 40000 datos a la clasificación, así que no veo muy válido el análisis en este caso.\n",
    "\n",
    "Se observa que en los casos 3 y 4 se obtuvo un error bastante grande reflejado en el f-score, esto en el contexto del problema es bien grave por estar lidiando con fraudes de tarjestas bancarias. Si observamos solo el valor del f-score en los 4 casos, el primero fue el que obtuvo un mayor valor de aprox 81 % y además tenía valores por sobre el 75% para precision y recall por lo que diría que fue el método más correcto entre los 4.\n",
    "\n",
    "Si tuviera que elegir entre las técnicas 3 y 4, preferiría la técnica 3 puesto que eliminar datos como en la técnica 4 en este caso lo encuentro sumamente perjudicial, se eliminaban casi 30000 datos en la clasificación, perdiendo una gran cantidad de información para un análisis posterior. En cambio en la técnica 4 no quitamos información pero si agregamos demsaidos datos que no estaban inicialmente.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
